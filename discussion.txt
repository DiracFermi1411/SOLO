We trained our current model for a total of 35 epochs on the entire dataset using the Google Colab Pro GPU (we were unable to run the code locally due to system/ cuda memory allocation constraints). Overall, the code required a lot of debugging to run effectively as intended. For example, in the first few train runs, we encountered the problem that the loss did not decrease with epochs which we finally attributed to an error in the loss function. Overall, our model generated good masks at appropriate locations. The performance and accuracy of our model could be improved further with additional compute resources and time. Choosing better model architectures (from literature) can also help boost the model performance as required.